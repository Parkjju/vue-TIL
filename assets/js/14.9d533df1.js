(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{298:function(t,s,a){t.exports=a.p+"assets/img/p1.27099e89.jpg"},339:function(t,s,a){t.exports=a.p+"assets/img/cut.3eef4ae1.jpg"},340:function(t,s,a){t.exports=a.p+"assets/img/cutex.6b3fd626.jpg"},341:function(t,s,a){t.exports=a.p+"assets/img/k1.c4a1ca15.jpg"},342:function(t,s,a){t.exports=a.p+"assets/img/k2.c68c84ba.jpg"},343:function(t,s,a){t.exports=a.p+"assets/img/k3.56e20ffb.jpg"},344:function(t,s,a){t.exports=a.p+"assets/img/k4.3388facd.jpg"},345:function(t,s,a){t.exports=a.p+"assets/img/k5.c6466641.jpg"},346:function(t,s,a){t.exports=a.p+"assets/img/k6.482e56f8.jpg"},347:function(t,s,a){t.exports=a.p+"assets/img/k7.47ed1708.jpg"},348:function(t,s,a){t.exports=a.p+"assets/img/k8.6bc86aee.jpg"},349:function(t,s,a){t.exports=a.p+"assets/img/prim.9ccd6c25.jpg"},350:function(t,s,a){t.exports=a.p+"assets/img/p2.bfb2173a.jpg"},351:function(t,s,a){t.exports=a.p+"assets/img/p3.38a3e9db.jpg"},682:function(t,s,a){"use strict";a.r(s);var n=a(6),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"최소신장트리-알고리즘"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#최소신장트리-알고리즘"}},[t._v("#")]),t._v(" 최소신장트리 알고리즘")]),t._v(" "),s("p",[t._v("최소신장트리(MST, Minimum Spanning Tree)는 그래프가 입력으로 주어지면 해당 그래프에 포함되어 있는 신장 트리의 비용이 최소인 그래프를 구하는 알고리즘이다.")]),t._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[t._v("신장트리란?")]),t._v(" "),s("p",[t._v("신장트리(Spanning tree)란 "),s("strong",[t._v("그래프의 부분 그래프로서")]),t._v(" 주어진 그래프의 "),s("strong",[t._v("모든 정점")]),t._v(" 과 간선의 부분 집합으로 구성되는 트리이다. 각 노드는 적어도 하나의 간선에 연결되어 있어야 하며 "),s("strong",[t._v("그래프에 사이클이 형성되면 안된다.")])])]),t._v(" "),s("h3",{attrs:{id:"mst-성질"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mst-성질"}},[t._v("#")]),t._v(" MST 성질")]),t._v(" "),s("ol",[s("li",[t._v("트리의 성질\n"),s("ul",[s("li",[t._v("n개의 노드는 n-1개의 간선을 갖는다.")]),t._v(" "),s("li",[t._v("에지가 삭제되면 2개의 부트리로 분할된다.")]),t._v(" "),s("li",[t._v("새로운 간선을 삽입하면 간선을 포함하는 사이클이 생성된다.")])])]),t._v(" "),s("li",[s("strong",[t._v("Cut Property")]),t._v(" : "),s("strong",[t._v("Prim algorithm")]),t._v(" "),s("ul",[s("li",[t._v("컷에서 최소 비용 간선을 포함하는 MST는 최소 하나 이상 존재한다.")])])])]),t._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[t._v("Cut이란?")]),t._v(" "),s("p",[t._v("그래프 내에 몇 개의 간선들을 모은 부분 집합을 의미한다. 컷에 해당하는 간선을 지우면 2개 이상의 부그래프로 나눠진다.")]),t._v(" "),s("p",[t._v("특정 기준에 따라 컷을 선정한 뒤 컷의 간선 모두를 그래프에서 제거한 뒤에 컷의 간선 하나씩 비용을 대입하며 최소 비용을 찾아보는 식으로 MST를 구성한다.")])]),t._v(" "),s("p",[s("img",{attrs:{src:a(339),alt:"cut"}})]),t._v(" "),s("p",[t._v("각 노드에서 뻗어 나가는 간선들을 확인하여 컷을 선정한 뒤 컷들 중 가장 작은 비용을 갖는 간선을 찾아 MST를 조사한다.")]),t._v(" "),s("p",[s("img",{attrs:{src:a(340),alt:"cutEx"}})]),t._v(" "),s("p",[t._v("부분 MST를 만든 뒤에 컷을 선정할 때에는 MST기준으로 인접한 간선을 모두 지나는 부드러운 곡선을 그려보면 된다.")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("Cycle Property")]),t._v(" : "),s("strong",[t._v("Kruskal algorithm")]),t._v(" "),s("ul",[s("li",[t._v("임의의 사이클의 최대 비용에지를 포함한 MST는 없다.")]),t._v(" "),s("li",[t._v("컷 프로퍼티와 반대로 생각하면 된다.")])])])]),t._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[t._v("사이클 프로퍼티 증명 (귀류법)")]),t._v(" "),s("p",[t._v("귀류법을 통해 최대비용 간선 e를 갖는 MST가 존재한다 라고 가정한다.")]),t._v(" "),s("p",[t._v("사이클 프로퍼티의 경우 두 간선 e, e'을 포함하는 그래프의 부분 사이클이 있고 간선 e의 비용이 간선 e'보다 크며 두 간선 중 하나만 삭제되어도 그래프가 신장트리로 나누어지는 상황을 생각해볼 때")]),t._v(" "),s("p",[t._v("이때 간선 e를 삭제하면 간선 e'로 이어지는 "),s("strong",[t._v("MST")]),t._v(" 가 만들어지게 되는데 이는 사이클 프로퍼티의 결론을 부정한 간선 e를 갖는 MST가 존재한다는 가정에 모순된다.")])]),t._v(" "),s("p",[t._v("다음은 크루스칼 알고리즘을 이용하여 MST를 찾는 과정이다.")]),t._v(" "),s("figure",{staticStyle:{display:"flex","align-items":"center","flex-direction":"column"}},[s("img",{attrs:{src:a(341),height:"80%",width:"80%"}}),t._v(" "),s("figcaption",{staticStyle:{"font-size":"1rem",color:"grey","font-weight":"bold","margin-top":"0.8rem","margin-bottom":"1rem"}},[t._v("1")]),t._v(" "),s("img",{attrs:{src:a(342),height:"80%",width:"80%"}}),t._v(" "),s("figcaption",{staticStyle:{"font-size":"1rem",color:"grey","font-weight":"bold","margin-top":"0.8rem","margin-bottom":"1rem"}},[t._v("2")]),t._v(" "),s("img",{attrs:{src:a(343),height:"80%",width:"80%"}}),t._v(" "),s("figcaption",{staticStyle:{"font-size":"1rem",color:"grey","font-weight":"bold","margin-top":"0.8rem","margin-bottom":"1rem"}},[t._v("3")]),t._v(" "),s("img",{attrs:{src:a(344),height:"80%",width:"80%"}}),t._v(" "),s("figcaption",{staticStyle:{"font-size":"1rem",color:"grey","font-weight":"bold","margin-top":"0.8rem","margin-bottom":"1rem"}},[t._v("4, 이때 a-b를 잇는 간선도 추가해야함!")]),t._v(" "),s("img",{attrs:{src:a(345),height:"80%",width:"80%"}}),t._v(" "),s("figcaption",{staticStyle:{"font-size":"1rem",color:"grey","font-weight":"bold","margin-top":"0.8rem","margin-bottom":"1rem"}},[t._v("5")]),t._v(" "),s("img",{attrs:{src:a(346),height:"80%",width:"80%"}}),t._v(" "),s("figcaption",{staticStyle:{"font-size":"1rem",color:"grey","font-weight":"bold","margin-top":"0.8rem","margin-bottom":"1rem"}},[t._v("6")]),t._v(" "),s("img",{attrs:{src:a(347),height:"80%",width:"80%"}}),t._v(" "),s("figcaption",{staticStyle:{"font-size":"1rem",color:"grey","font-weight":"bold","margin-top":"0.8rem","margin-bottom":"1rem"}},[t._v("7")]),t._v(" "),s("img",{attrs:{src:a(348),height:"80%",width:"80%"}}),t._v(" "),s("figcaption",{staticStyle:{"font-size":"1rem",color:"grey","font-weight":"bold","margin-top":"0.8rem","margin-bottom":"1rem"}},[t._v("8")])]),t._v(" "),s("h2",{attrs:{id:"프림-알고리즘"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#프림-알고리즘"}},[t._v("#")]),t._v(" 프림 알고리즘")]),t._v(" "),s("p",[t._v("컷 프로퍼티(Cut property) : 컷의 최소비용에지를 포함한 MST는 항상 존재한다.")]),t._v(" "),s("p",[t._v("프림 알고리즘 구현을 위해 F는 임의의 노드 u, T는 공집합으로 시작한다.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# pseudo code")]),t._v("\nF "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nT "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ∅\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("T"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    find "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("min")]),t._v(" edge"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" such that\n    u ∈ F "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" v ∈ V"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("F\n\n    T "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T ∪ "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    F "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F ∪ "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" T\n")])])]),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[t._v("정리")]),t._v(" "),s("p",[t._v("F에 속하는 u노드에서 뻗어 나가는 간선들 중, u의 인접한 노드 v의로의 가중치가 가장 작은 간선을 찾은 후 T에 간선 (u,v)를 추가하고 F에는 v를 추가한다.")])]),t._v(" "),s("p",[s("img",{attrs:{src:a(349),alt:"prim"}})]),t._v(" "),s("p",[t._v("F와 V-F 사이에 컷에 해당하는 간선들 중 최소비용을 갖도록 간선을 구성한다. V-F에서 컷에 해당하는 노드를 제외한 나머지 노드의 가중치는 모두 무한대로 초기화해둔 상태이다.")]),t._v(" "),s("p",[t._v("컷들 중 최소비용 간선에 해당하는 노드 둘 중 F에 속하는 노드가 E[v], V-F에 속하는 노드가 cost[v]로 정의된다.")]),t._v(" "),s("p",[t._v("V-F에 속하는 cost리스트는 무한대로, F에 속하는 E리스트는 None으로 초기화해둔다. 최종적으로 cost값이 가장 작은 노드를 찾아내기 위해 최소 힙 자료구조를 이용한다.")]),t._v(" "),s("p",[t._v("조건을 만족하여 T에 간선이 추가될때마다 기존에 V-F에 속했던 노드가 이제는 "),s("strong",[t._v("F에 속하게 되므로")]),t._v(" 컷에 해당하는 또 다른 간선을 만들기 위해 F에 추가된 새로운 노드로부터 V-F로의 간선 이동에서 "),s("strong",[t._v("릴랙스 연산을 진행해야 한다.")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# prim pseudo code with detail code")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" each node v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    cost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" math"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inf\n    E"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n    F"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\nT "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nQ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Heap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("V"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# cost가 키값")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" Q "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" empty"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 초기에 Q는 모든 노드가 무한대인 상태이므로 무작위 노드가 삭제된다.")]),t._v("\n    v "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("delete_min"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    F"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" E"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        T"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appennd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("E"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" each edge "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" incident to v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" F"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" cost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" cost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            cost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            Q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decrease_key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            E"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" v\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" T\n")])])]),s("div",{staticClass:"custom-block warning"},[s("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),s("p",[t._v("프림 알고리즘에서의 힙 자료구조는 우선순위 큐(Priority Queue)를 이용한다. 이에 해당하는 힙 자료구조로는 바이너리 힙(통상 알고있는 힙), 피보나치 힙 등이 있다.")])]),t._v(" "),s("p",[s("img",{attrs:{src:a(298),alt:"prim"}}),s("br"),t._v(" "),s("img",{attrs:{src:a(350),alt:"prim"}}),s("br"),t._v(" "),s("img",{attrs:{src:a(351),alt:"prim"}})]),t._v(" "),s("p",[t._v("수행시간은 n을 노드 수 m을 간선 수라고 하였을 때")]),t._v(" "),s("ol",[s("li",[t._v("힙을 만드는 시간 O(n)")]),t._v(" "),s("li",[t._v("바깥 while 루프의 경우 O(n)")]),t._v(" "),s("li",[t._v("while 내부의 for 루프 O(logn)")]),t._v(" "),s("li",[t._v("decrease key O(logn)")]),t._v(" "),s("li",[t._v("최악의 경우 for루프 내의 decrease key가 간선 수만큼 (m)번 호출")])]),t._v(" "),s("p",[t._v("O(nlogn + mlogn) = O((m+n)logn)")]),t._v(" "),s("h2",{attrs:{id:"크루스칼-알고리즘"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#크루스칼-알고리즘"}},[t._v("#")]),t._v(" 크루스칼 알고리즘")]),t._v(" "),s("p",[t._v("사이클 프로퍼티(Cycle property) : 임의 사이클의 최대비용 간선은 MST에 포함되지 않는다.")]),t._v(" "),s("p",[t._v("크루스칼 알고리즘은 크게 다음과 같은 과정으로 진행된다.")]),t._v(" "),s("ol",[s("li",[t._v("간선을 비용의 오름차순으로 정렬한다.")]),t._v(" "),s("li",[t._v("최소 비용의 간선부터 MST를 만들어가되 "),s("strong",[t._v("사이클이 형성되면 안된다.")])]),t._v(" "),s("li",[t._v("작은 트리들이 서로 연결되어 하나의 큰 MST를 형성하게 된다는 것에서 의미를 가져와 크루스칼 알고리즘의 부트리를 "),s("strong",[t._v("Forest(A collection of tree)")]),t._v(" 라고 칭한다.")]),t._v(" "),s("li",[t._v("모든 간선을 검사할 필요 없이 현재까지 포레스트에 쌓인 노드의 수가 전체 그래프의 노드 수와 동일해지면 연산을 종료하면 된다.")])]),t._v(" "),s("p",[t._v("2번과정에서 추가했던 간선이 트리의 사이클 형성 원인이 되었을 때 해당 간선의 비용을 보면 현재까지 만들어온 포레스트의 간선 비용 중 가장 큰 값을 가지게 된다. 사이클 프로퍼티에 따라 현재 발견된 최대비용 간선은 앞으로 MST에 포함될 일이 없으므로 제외하여 다음 연산을 시작하면 된다.")]),t._v(" "),s("p",[t._v("포레스트의 사이클 여부 검사하는 데에 사용되는 자료구조는 "),s("strong",[t._v("union-find")]),t._v(" 자료구조가 사용되며 총 수행시간은 m개의 간선이 있을 때 O(mlogm)시간이 소요된다.")]),t._v(" "),s("h3",{attrs:{id:"코드구현"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#코드구현"}},[t._v("#")]),t._v(" 코드구현")]),t._v(" "),s("p",[t._v("크루스칼 연산 이전 자료의 초기 상태는 그래프의 각 노드를 모두 집합화 하는 것이다."),s("br"),t._v(" "),s("img",{attrs:{src:a(298),alt:"prim"}})]),t._v(" "),s("p",[t._v("{a}, {b}, {c} ... {h}, {i}")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("kruskal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("V"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" E"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    T "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" each v ∈ V"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# n*O(1) -> O(n)")]),t._v("\n        make_set"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# O(1)")]),t._v("\n    sort E "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" 오름차순 of costs "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# merge sort or heap sort, O(mlogm) - merge sort")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" each e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" E"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# m")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" find"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" ≠ find"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u가 속한 집합, v가 속한 집합이 같은지 여부를 검사 O(logn)")]),t._v("\n            T"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            union"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("find"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" find"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# union-find의 연산")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# O(mlogn)")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" T\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 총 수행시간 O(mlogm)")]),t._v("\n")])])]),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# union-find")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# pseudo code")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Node")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" key\n        self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self\n        self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rank "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("makeset")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" Node"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("find")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# x의 루트노드 리턴")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# x is not root")]),t._v("\n        x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" x\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("union")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" w "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" find"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" find"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rank "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rank"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" w "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# rank가 작은 쪽에서 rank가 큰 쪽으로 트리를 연결, swap의 필요성?")]),t._v("\n    v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" w\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rank"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v("w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rank"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rank"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);