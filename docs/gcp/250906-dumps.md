---
title: Google Cloud Platform - GCP 덤프 정리
---

## dump 1

Every employee of your company has a Google account. Your operational team needs to manage a large number of instances on Compute Engine. Each member of this team needs only administrative access to the servers. Your security team wants to ensure that the deployment of credentials is operationally efficient and must be able to determine who accessed a given instance. What should you do?

A. Generate a new SSH key pair. Give the private key to each member of your team. Configure the public key in the metadata of each instance.
B. Ask each member of the team to generate a new SSH key pair and to send you their public key. Use a configuration management tool to deploy those keys on each instance.
C. Ask each member of the team to generate a new SSH key pair and to add the public key to their Google account. Grant the ג€compute.osAdminLoginג€ role to the Google group corresponding to this team.
D. Generate a new SSH key pair. Give the private key to each member of your team. Configure the public key as a project-wide public SSH key in your Cloud Platform project and allow project-wide public SSH keys on each instance.

:::details 풀이

문제 해석) 회사의 모든 직원이 Google 계정을 가지고 있습니다. 운영팀은 Compute Engine에서 많은 수의 인스턴스를 관리해야 합니다. 이 팀의 각 구성원은 서버에 대한 관리자 액세스 권한만 필요합니다. 보안팀은 자격 증명 배포가 운영상 효율적이어야 하며 누가 특정 인스턴스에 액세스했는지 확인할 수 있어야 한다고 요구합니다. 어떻게 해야 할까요?

서버에 대한 관리자 액세스 권한이라 함은, Compute Engine 서버 내에서 시스템 관리 작업에 대한 권한을 의미한다. 리소스 관리 권한이 아닌 것을 기억해야 한다.

오답 정리

-   A(오답): 새로운 SSH 키 쌍을 생성하고, 개인 키를 팀의 각 구성원에게 제공하며, 각 인스턴스의 메타데이터에 공개 키를 구성
    -   동일한 개인 키를 공유하면 누가 접근했는지 추적 불가
-   B(오답): 각 팀 구성원이 새로운 SSH 키 쌍을 생성하고 공개 키를 보내도록 하여, 구성 관리 도구로 각 인스턴스에 배포
    -   수동 배포 과정 비효율 / 확장성 저하
-   **C(정답)**: 각 팀 구성원이 새로운 SSH 키 쌍을 생성하고 Google 계정에 공개 키를 추가하도록 하고, 해당 팀에 대응하는 Google 그룹에 'compute.osAdminLogin' 역할을 부여
    -   OS Login을 통해 Google 계정과 SSH 키가 연동됨
    -   각 사용자를 개별적으로 추적 가능
    -   그룹 기반 권한 관리로 효율적
    -   Google의 감사 로그를 통해 접근 기록 추적 가능
-   D(오답): 새로운 SSH 키 쌍을 생성하고 개인 키를 각 구성원에게 제공하며, 프로젝트 전체 공개 SSH 키로 구성
    -   A와 동일하게 개별 사용자 추적 불가능

:::

## dump 2

```
You need to create a custom VPC with a single subnet. The subnet's range must be as large as possible. Which range should you use?

A. 0.0.0.0/0
B. 10.0.0.0/8
C. 172.16.0.0/12
D. 192.168.0.0/16
```

:::details 풀이

사용자 정의 VPC를 단일 서브넷으로 생성해야 합니다. 서브넷의 범위는 가능한 한 커야 합니다. 어떤 범위를 사용해야 할까요?

CIDR이란 IP 주소를 효율적으로 할당하고 라우팅하기 위한 방법이다. (`IP주소/프리픽스길이`)

A. 0.0.0.0/0

의미: 전체 IPv4 주소 공간 (모든 IP 주소)
범위: 0.0.0.0 ~ 255.255.255.255
주소 개수: 약 43억 개

B. 10.0.0.0/8 ⭐

의미: RFC 1918 사설 IP 대역 중 Class A
범위: 10.0.0.0 ~ 10.255.255.255
주소 개수: 약 1,677만 개

C. 172.16.0.0/12

의미: RFC 1918 사설 IP 대역 중 Class B
범위: 172.16.0.0 ~ 172.31.255.255
주소 개수: 약 104만 개

D. 192.168.0.0/16

의미: RFC 1918 사설 IP 대역 중 Class C
범위: 192.168.0.0 ~ 192.168.255.255
주소 개수: 약 6만 5천 개

CIDR 표기에서 192.168.1.100/24의 앞부분은 IP주소, 뒷부분은 서브넷마스크 길이이다. 192, 168과 같은 각 부분은 옥텟이라고 불린다. 각 옥텟마다 0~255까지 할당 가능한데, 이는 비트 기준 00000000 ~ 11111111로 값이 변할 수 있다는 것을 가리킨다.

서브넷 마스크 길이는 1의 갯수를 의미하고, /24면 비트 1이 24개가 고정이라는 것을 의미한다.

즉 192.168.1이 고정 주소이고, 나머지 100 주소값이 변할 수 있음을 의미한다.

:::

## dump 3

You want to select and configure a cost-effective solution for relational data on Google Cloud Platform. You are working with a small set of operational data in one geographic location. You need to support point-in-time recovery. What should you do?

-   A. Select Cloud SQL (MySQL). Verify that the enable binary logging option is selected.
-   B. Select Cloud SQL (MySQL). Select the create failover replicas option.
-   C. Select Cloud Spanner. Set up your instance with 2 nodes.
-   D. Select Cloud Spanner. Set up your instance as multi-regional.

:::details 풀이

## 영문 문제 해석

**문제**: "Google Cloud Platform에서 관계형 데이터를 위한 비용 효율적인 솔루션을 선택하고 구성하려고 합니다. 한 지리적 위치에서 소규모 운영 데이터로 작업하고 있습니다. 특정 시점 복구(point-in-time recovery)를 지원해야 합니다. 어떻게 해야 할까요?"

**핵심 요구사항**:

-   관계형 데이터베이스
-   **비용 효율적인** 솔루션
-   **소규모** 운영 데이터
-   **단일 지리적 위치**
-   **Point-in-time Recovery (PITR)** 지원 필수

## 선택지 해석

**A. Cloud SQL (MySQL)을 선택하고, enable binary logging 옵션이 선택되었는지 확인**

-   Binary logging: MySQL의 변경 사항을 로그로 기록
-   PITR을 위해 필수적인 기능

**B. Cloud SQL (MySQL)을 선택하고, create failover replicas 옵션을 선택**

-   Failover replicas: 고가용성을 위한 복제본 생성
-   주로 장애 대응용, PITR과는 다른 개념

**C. Cloud Spanner를 선택하고, 2개 노드로 인스턴스 설정**

-   Cloud Spanner: 글로벌 분산 데이터베이스
-   최소 2개 노드 필요 (비용이 높음)

**D. Cloud Spanner를 선택하고, 인스턴스를 멀티 리전으로 설정**

-   Multi-regional: 여러 지역에 분산
-   가장 비용이 높은 옵션

## 문제 분석 및 정답 도출

### 서비스 비교

**Cloud SQL vs Cloud Spanner**

-   **Cloud SQL**:
-   소규모~중간 규모 애플리케이션
-   비용 효율적
-   단일 리전에 적합
-   PITR 지원 (binary logging 필요)

-   **Cloud Spanner**:
-   대규모, 글로벌 애플리케이션
-   비용이 높음 (최소 2노드부터)
-   자동 PITR 지원하지만 과도한 스펙

### Point-in-Time Recovery

**Cloud SQL에서 PITR 활성화 방법**:

1. **Binary logging 활성화** ← 핵심!
2. Automated backup 설정
3. 이 둘이 결합되어 PITR 기능 제공

**Failover replicas**는 고가용성을 위한 것으로 PITR과는 별개입니다.

### 비용 고려사항

-   **소규모 데이터 + 단일 위치** → Cloud SQL이 적합
-   Cloud Spanner는 요구사항 대비 과도하게 비싼 솔루션

### 정답: **A. Cloud SQL (MySQL)을 선택하고, enable binary logging 옵션이 선택되었는지 확인**

**선택 이유**:

1. **비용 효율성**: 소규모 데이터에는 Cloud SQL이 적합
2. **PITR 지원**: Binary logging이 PITR의 핵심 요구사항
3. **단일 위치**: 멀티 리전 불필요
4. **요구사항 충족**: 모든 조건을 가장 경제적으로 만족

:::

## dump 4

You want to configure autohealing for network load balancing for a group of Compute Engine instances that run in multiple zones, using the fewest possible steps. You need to configure re-creation of VMs if they are unresponsive after 3 attempts of 10 seconds each. What should you do?

-   A. Create an HTTP load balancer with a backend configuration that references an existing instance group. Set the health check to healthy (HTTP)
-   B. Create an HTTP load balancer with a backend configuration that references an existing instance group. Define a balancing mode and set the maximum RPS to 10.
-   C. Create a managed instance group. Set the Autohealing health check to healthy (HTTP)
-   D. Create a managed instance group. Verify that the autoscaling setting is on.

:::details 풀이

## 영문 문제 해석

**문제**: "여러 영역에서 실행되는 Compute Engine 인스턴스 그룹에 대해 네트워크 로드 밸런싱을 위한 자동 복구(autohealing)를 가능한 한 최소한의 단계로 구성하려고 합니다. 각각 10초씩 3회 시도 후 응답하지 않으면 VM을 다시 생성하도록 구성해야 합니다. 어떻게 해야 할까요?"

**핵심 요구사항**:

-   **Autohealing** (자동 복구) 구성
-   **Network load balancing**
-   **Multiple zones** (여러 영역)
-   **최소 단계**로 구성
-   **3회 시도 × 10초 = 30초** 후 VM 재생성
-   응답하지 않는 VM 처리

## 선택지 해석

**A. 기존 인스턴스 그룹을 참조하는 백엔드 구성으로 HTTP 로드 밸런서 생성. 헬스 체크를 healthy (HTTP)로 설정**

-   HTTP 로드 밸런서: L7 로드 밸런서 (문제에서 요구하는 것은 네트워크 로드 밸런싱)
    -   L7 - OSI 7계층을 의미, HTTP 로드밸런서는 7계층인데, 문제에서 요구하는건 네트워크 계층 (4계층) 로드밸런서
-   기존 인스턴스 그룹 사용 (autohealing 기능 없음)
    -   문제에서의 existing instance group이 unmanaged instance group을 의미한다.

**B. 기존 인스턴스 그룹을 참조하는 백엔드 구성으로 HTTP 로드 밸런서 생성. 밸런싱 모드 정의하고 최대 RPS를 10으로 설정**

-   HTTP 로드 밸런서 (네트워크 로드 밸런싱 아님)
-   RPS 설정은 autohealing과 무관

**C. 관리형 인스턴스 그룹(Managed Instance Group) 생성. Autohealing 헬스 체크를 healthy (HTTP)로 설정**

-   MIG: autohealing 기능 내장
-   헬스 체크로 자동 복구 가능

**D. 관리형 인스턴스 그룹 생성. 오토스케일링 설정이 켜져 있는지 확인**

-   MIG 생성은 맞지만
-   Autoscaling ≠ Autohealing (다른 기능)

## 문제 분석 및 정답 도출

### Autohealing vs Load Balancing 구분

**Autohealing (자동 복구)**:

-   비정상 인스턴스를 **자동으로 재생성**
-   Managed Instance Group의 기능
-   Health check로 인스턴스 상태 모니터링

**Load Balancing**:

-   트래픽을 여러 인스턴스에 **분산**
-   비정상 인스턴스로 트래픽 전송 중단
-   인스턴스를 재생성하지는 않음

### Network Load Balancing

문제에서 "network load balancing"을 언급했지만, 핵심 요구사항은 **autohealing**입니다.

-   Network LB 자체는 autohealing 기능 없음
-   MIG + Health Check = autohealing 구현

### Managed Instance Group (MIG)의 장점

1. **Autohealing 내장**: 헬스 체크 기반 자동 복구
2. **Multi-zone 지원**: 여러 영역에 인스턴스 분산
3. **최소 단계**: 한 번의 설정으로 모든 기능 활성화
4. **Health Check 커스터마이징**: 3회 × 10초 설정 가능

### 헬스 체크 설정

MIG에서 autohealing 설정 시:

Check interval: 10초
Timeout: 10초
Unhealthy threshold: 3회
총 대기 시간: 30초 후 VM 재생성

### 정답: **C. 관리형 인스턴스 그룹 생성. Autohealing 헬스 체크를 healthy (HTTP)로 설정**

**선택 이유**:

1. **Autohealing 직접 제공**: MIG는 autohealing 기능을 내장
2. **최소 단계**: 하나의 구성으로 모든 요구사항 충족
3. **Multi-zone 지원**: 자동으로 여러 영역에 분산
4. **헬스 체크 커스터마이징**: 3회 × 10초 설정 가능
5. **요구사항 완벽 일치**: VM 재생성 기능 제공

오토힐링 헬스체크 타입을 HTTP 지정한다는 것은 HTTP 요청을 보낸 뒤 응답 코드를 보고 상태를 판단한다는 것을 의미한다.

-   TCP: 포트 연결만 확인
-   HTTPS: SSL/TLS 포함한 HTTP 확인
-   HTTP/2: HTTP/2 프로토콜로 확인

:::

## dump 5

You are using multiple configurations for gcloud. You want to review the configured Kubernetes Engine cluster of an inactive configuration using the fewest possible steps. What should you do?

-   A. Use gcloud config configurations describe to review the output.
-   B. Use gcloud config configurations activate and gcloud config list to review the output.
-   C. Use kubectl config get-contexts to review the output.
-   D. Use kubectl config use-context and kubectl config view to review the output.

:::details 풀이

## 영문 문제 해석

**문제**: "gcloud에 대해 여러 구성을 사용하고 있습니다. 가장 적은 단계로 비활성 구성의 구성된 Kubernetes Engine 클러스터를 검토하려고 합니다. 어떻게 해야 할까요?"

**핵심 요구사항**:

-   Multiple gcloud configurations (여러 gcloud 구성)
-   Inactive configuration (비활성 구성)
-   Kubernetes Engine cluster 검토
-   Fewest possible steps (최소 단계)

## 선택지 해석

**A. gcloud config configurations describe를 사용하여 출력 검토**

-   특정 구성의 모든 속성을 표시
-   구성 활성화 없이 바로 확인 가능

**B. gcloud config configurations activate와 gcloud config list를 사용하여 출력 검토**

-   구성 활성화 후 현재 활성 구성 확인
-   2단계 필요

**C. kubectl config get-contexts를 사용하여 출력 검토**

-   kubectl의 컨텍스트 목록 확인
-   gcloud 구성과는 별개의 kubectl 구성

**D. kubectl config use-context와 kubectl config view를 사용하여 출력 검토**

-   kubectl 컨텍스트 변경 후 클러스터 구성 정보 확인
-   2단계 필요

## 문제 분석 및 정답 도출

### gcloud configuration vs kubectl context

**gcloud configuration**

-   Google Cloud CLI의 구성 프로필
-   프로젝트, 리전, 계정, 클러스터 이름 등 설정

**kubectl context**

-   Kubernetes CLI의 클러스터 접속 정보
-   클러스터 API 서버, 인증 정보, 네임스페이스 등

### "configured Kubernetes Engine cluster를 review"의 의미

**실제 Kubernetes 클러스터 구성 확인**

-   클러스터 API 서버 주소
-   인증 정보 및 방식
-   네임스페이스 설정
-   사용자 권한 정보

### 각 선택지 분석

**A. gcloud config configurations describe**

-   출력: 프로젝트, 리전, 클러스터 이름
-   한계: 실제 Kubernetes 구성 정보 없음

**B. gcloud config configurations activate + list**

-   출력: gcloud 레벨 정보
-   한계: Kubernetes 클러스터 구성 세부사항 없음

**C. kubectl config get-contexts**

-   출력: 컨텍스트 목록
-   한계: 실제 클러스터 구성 정보 없음

**D. kubectl config use-context + view**

-   출력: 클러스터 API 서버, 인증 정보, 사용자 설정 등
-   장점: 실제 Kubernetes 클러스터 구성 정보 제공

### 정답: D. kubectl config use-context와 kubectl config view를 사용하여 출력 검토

**선택 이유**:

1. 실제 Kubernetes 클러스터 구성 정보 확인 가능
2. API 서버 주소, 인증 방식, 사용자 권한 등 상세 정보 제공
3. kubectl config view가 클러스터 구성 검토에 적합한 명령어
4. gcloud configuration은 메타 정보만 제공하여 부족

:::
